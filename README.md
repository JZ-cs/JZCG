# A few words
这是一个很简易的框架，很多功能都待完善和添加。在有像PyTorch, TensorFlow等这么成熟和完善的框架以及各大公司也有各自自研框架的现在，重复造这个轮子有什么意义呢？当然我觉得教育意义还是有一点的，毕竟现在是人工智能的时代，每个人都能借助实现这样一个玩具，加深下深度学习的基础。依稀记得在当时写个全连接的反向传播应该算是深度学习的"Hello World"吧。 

代码不多，几千行，使用Java编写(当时主要是想熟悉下Java)，早期是VSCode搭的环境，后期转到IDEA了。

##### 已实现的如下：
1. 基本操作：加减乘除和矩阵乘法，已经废弃的dot操作;
2. reduce操作：sum, max(min还没写^_^);
3. 功能性操作：transpose, squeeze, unsqueeze;
4. 函数操作实现比较简单，因此只实现了exp, log, sigmoid, 后续可以轻易添加其他函数实现；
5. 损失函数目前只有MSE，后续有空会添加其他的。
6. 一个简单的Module模块，目的在于后续复杂的实现比如全连接层，卷积层以及自定义的模型都应该在继承它的基础上实现，这样只需要实现模型的搭建，完成前向传播的逻辑，类似PyTorch, 不需要考虑反向传播的问题。


除了功能性操作（不涉及具体数据的改变，只涉及维度操作，实现反向传播应该不难），完成了相关类的实现，内嵌了前向传播的逻辑和反向求导的逻辑，可用来构建计算图。所有操作都支持多维张量，也都支持广播操作。

##### 目前已实现但还未完善：
1.  单核的训练方式，多线程模型一个简单的思路是构建一个DAG的degree table, 叶子结点的degree均为0，根据拓扑排序往上递增，这时呈现一个金子塔的层级结构，同一层的均可以同时计算，下一层的可以不断去遍历，在当前层的部分完成后也可以启动计算。
1.  数据分布式训练, 整个模型可以容纳在一台机器内，只做数据上的并行训练，训练过程中梯度交换策略为Ring Allreduce，只在3台linux云服务器或者轻量应用服务器上测试过，其中网络传输梯度完全可以继续优化。
2.  模型分布式训练，分散整个模型在不同机器训练，只实现了部分，主要瓶颈和未实现的部分在于: 怎么更好地分割整个模型，尽可能满足负载均衡，提升并行度和减少不必要的网络传输， 以及后续的高可用。

### 大佬轻喷，欢迎提出意见，不论是关于Java的，还是实现上的，直接拉分支当然更好。
