# A few words
说来惭愧，研究生期间没啥拿得出手的成果，唯一写过的代码行数比较多的又只有这个项目。现在想想，自己研究生期间到底做了什么呢？也许正是因为这样，所以花在这里的时间远超出了自己的预期，因为自己拿得出手，能说说的也就是这个了。不过然并卵，这仍旧是个没什么价值的框架，之所以说它没什么价值，是因为已经有像PyTorch, TensorFlow等这么成熟和完善的框架了，各大公司也有自研的，而这个目前大部分只有功能实现，也只能使用cpu训练。唯一能说说的大概也就是教育意义？因为每个人都能借助实现这样一个玩具，加深下深度学习的基础。依稀记得在当时写个全连接的反向传播应该算是深度学习的"Hello World"吧。 

代码不多，几千行，使用Java编写(当时主要是想熟悉下Java)，早期是VSCode搭的环境，后期转到IDEA了。

##### 已实现的如下：
1. 基本操作：加减乘除和矩阵乘法，已经废弃的dot操作;
2. reduce操作：sum, max(min还没写^_^);
3. 功能性操作：transpose, squeeze, unsqueeze;
4. 函数操作实现比较简单，因此只实现了exp, log, sigmoid, 后续可以轻易添加其他函数实现；
5. 损失函数目前只有MSE，后续有空会添加其他的。
6. 一个简单的Module模块，目的在于后续复杂的实现比如全连接层，卷积层以及自定义的模型都应该在继承它的基础上实现，这样只需要实现模型的搭建，完成前向传播的逻辑，类似PyTorch, 不需要考虑反向传播的问题。


除了功能性操作（不涉及具体数据的改变，只涉及维度操作，实现反向传播应该不难），完成了相关类的实现，内嵌了前向传播的逻辑和反向求导的逻辑，可用来构建计算图。所有操作都支持多维张量，也都支持广播操作。

##### 目前已实现但还未完善：
1.  单核的训练方式，多线程模型一个简单的思路是构建一个DAG的degree table, 叶子结点的degree均为0，根据拓扑排序往上递增，这时呈现一个金子塔的层级结构，同一层的均可以同时计算，下一层的可以不断去遍历，在当前层的部分完成后也可以启动计算。
1.  数据分布式训练, 整个模型可以容纳在一台机器内，只做数据上的并行训练，训练过程中梯度交换策略为Ring Allreduce，只在3台linux云服务器或者轻量应用服务器上测试过，其中网络传输梯度完全可以继续优化。
2.  模型分布式训练，分散整个模型在不同机器训练，只实现了部分，主要瓶颈和未实现的部分在于: 怎么更好地分割整个模型，尽可能满足负载均衡，提升并行度和减少不必要的网络传输， 以及后续的高可用。

### 大佬轻喷，欢迎提出意见，不论是关于Java的，还是实现上的，直接拉分支当然更好。
